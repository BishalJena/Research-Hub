# ðŸš€ API Migration Plan - From Local Models to Cloud APIs

**Date**: November 3, 2025
**Status**: Ready for Implementation
**Timeline**: 2-4 hours implementation
**Impact**: 10x faster, 95% smaller footprint, instant startup

---

## ðŸ“‹ Executive Summary

Migrating from heavyweight local AI models (7-8 GB) to cloud-based APIs to achieve:

âœ… **Instant startup** (0s vs 6-17 minutes)
âœ… **Faster responses** (200-500ms vs 2-5 seconds)
âœ… **95% smaller installation** (~400 MB vs 8 GB)
âœ… **Better accuracy** (GPT-4/Claude vs open-source models)
âœ… **True scalability** (handle 1000+ concurrent users)

---

## ðŸŽ¯ Migration Strategy

### Phase 1: Core Services (High Priority)
- Literature Review Service â†’ **OpenRouter API using gemini 2.5 flash**
- Plagiarism Detection â†’ **Cohere Embeddings API**
- Journal Recommendation â†’ **Cohere Embeddings API**
- Translation Service â†’ **Bhashini API** (Government of India - FREE!)

### Phase 2: Infrastructure (Medium Priority)
- Update requirements.txt
- Add API configuration
- Update Docker setup
- Add fallback mechanisms

### Phase 3: Documentation (Medium Priority)
- Update README
- Update ARCHITECTURE
- Create API setup guide
- Update deployment docs

---

## ðŸ”„ Service-by-Service Migration

### 1. Literature Review Service

**Current**: BART-large-CNN (~1.6 GB)
**New**: gemini 2.5 flash (OpenRouter API)

**Why**:
- 10x faster (200ms vs 2-5s)
- Better quality summaries
- No download/loading time
- Handles longer texts (16k tokens vs 1024)


**Cost**: ~$0.002 per summary (500 summaries = $1)

---

### 2. Plagiarism Detection Service

**Current**: Sentence-BERT all-mpnet-base-v2 (~420 MB)
**New**: Cohere Embed API (Free tier: 1000 requests/month)

**Why**:
- Instant embedding generation
- Better semantic understanding
- Free tier sufficient for PoC
- No model loading time

**Implementation**:
```python
# Before
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-mpnet-base-v2')
embedding = model.encode(text)

# After
import cohere
co = cohere.Client(os.getenv("COHERE_API_KEY"))
response = co.embed(
    texts=[text],
    model='embed-english-v3.0',
    input_type='search_document'
)
embedding = response.embeddings[0]
```

**Cost**: Free tier (1000 embeds/month), then $0.0001 per embed

---

### 3. Journal Recommendation Service

**Current**: SPECTER (~440 MB)
**New**: Cohere Embed API

**Why**:
- Same API as plagiarism (code reuse)
- Better semantic matching
- Instant results
- Scalable to 1000+ journals

**Implementation**: Same as plagiarism detection above

**Cost**: Shared with plagiarism detection (free tier)

---

### 4. Translation Service

**Current**: IndicTrans2 (~4 GB for both models)
**New**: Bhashini API (Government of India)

**Why**:
- **FREE** - Government-backed service
- Supports Telugu, Hindi, Urdu, Sanskrit
- Purpose-built for Indian languages
- No download/loading time
- Official government support (great for pitch!)

**Implementation**:
```python
# Before
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
model = AutoModelForSeq2SeqLM.from_pretrained("ai4bharat/indictrans2-en-indic-1B")
tokenizer = AutoTokenizer.from_pretrained("ai4bharat/indictrans2-en-indic-1B")

# After
import requests

def translate_bhashini(text, source_lang, target_lang):
    url = "https://bhashini-api.example.com/translate"  # Replace with actual endpoint
    response = requests.post(url, json={
        "text": text,
        "source": source_lang,
        "target": target_lang
    })
    return response.json()["translated_text"]
```

**Alternative**: Google Cloud Translation API (~$20/1M characters)

**Cost**: **FREE** with Bhashini (Government service)

---

## ðŸ“¦ Updated Dependencies

### Current requirements.txt (Heavy)
```txt
transformers>=4.35.2          # 2.5 GB
torch>=2.6.0                  # 2.8 GB
sentence-transformers>=2.7.0  # 500 MB + dependencies
Total: ~8 GB
```

### New requirements-api.txt (Lightweight)
```txt
# Core Framework (unchanged)
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# Database (unchanged)
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.12.1

# Authentication (unchanged)
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0

# Task Queue (unchanged)
celery==5.3.4
redis==5.0.1

# API Clients (NEW!)
openai==1.3.5                 # OpenAI API
cohere==4.37                  # Cohere API
anthropic==0.7.1              # Claude API (optional)

# Academic APIs (unchanged)
requests==2.31.0
aiohttp==3.9.1

# PDF Processing (unchanged)
PyPDF2==3.0.1
pdfplumber==0.10.3

# Data Processing (unchanged)
pandas>=2.0.0
numpy>=1.24.0

# Utilities (unchanged)
python-dateutil==2.8.2
pytz==2023.3
pydantic==2.5.0
pydantic-settings==2.1.0

# Testing (unchanged)
pytest==7.4.3
pytest-asyncio==0.21.1
httpx==0.25.2

Total: ~400 MB (95% reduction!)
```

---

## ðŸ” API Keys Required

### For PoC (8 users, 2 months)

1. **OpenAI API Key** (Required)
   - Sign up: https://platform.openai.com
   - Cost: $5-20 for PoC
   - Free $5 credit on signup
   - Models: gpt-3.5-turbo (summarization)

2. **Cohere API Key** (Required)
   - Sign up: https://cohere.com
   - Cost: **FREE** (Trial tier sufficient)
   - Free tier: 1000 API calls/month
   - Models: embed-english-v3.0 (embeddings)

3. **Bhashini API Key** (Recommended)
   - Sign up: https://bhashini.gov.in/ulca
   - Cost: **FREE** (Government service)
   - Models: IndicTrans2, IndicBERT
   - **Alternative**: Google Translate API ($20/1M chars)

4. **Semantic Scholar API** (Already using)
   - No key required
   - Free, rate-limited

---

## ðŸ› ï¸ Implementation Steps

### Step 1: Install New Dependencies (5 minutes)
```bash
cd backend
pip install openai==1.3.5 cohere==4.37
# Remove heavy dependencies
pip uninstall transformers torch sentence-transformers
```

### Step 2: Add API Keys to .env (2 minutes)
```bash
# .env file
OPENAI_API_KEY=sk-...
COHERE_API_KEY=...
BHASHINI_API_KEY=...
BHASHINI_USER_ID=...
```

### Step 3: Update Services (60-90 minutes)

**Files to modify**:
1. `app/services/literature_review_service.py` - Replace BART with OpenAI
2. `app/services/plagiarism_detection_service.py` - Replace Sentence-BERT with Cohere
3. `app/services/journal_recommendation_service.py` - Replace SPECTER with Cohere
4. `app/services/translation_service.py` - Replace IndicTrans2 with Bhashini

### Step 4: Add Error Handling (30 minutes)
- API rate limit handling
- Retry logic with exponential backoff
- Fallback to simple algorithms if API fails

### Step 5: Testing (30 minutes)
- Test each service individually
- Integration tests
- Load testing (simulate 8 concurrent users)

### Step 6: Documentation (30 minutes)
- Update README
- Update ARCHITECTURE
- Create API setup guide

**Total Time**: 2-4 hours

---

## ðŸ’° Cost Estimate (PoC: 8 Users, 2 Months)

### Pessimistic Scenario (Heavy Usage)
| Service | Usage | Cost |
|---------|-------|------|
| OpenAI (Summarization) | 500 papers Ã— $0.002 | $1.00 |
| Cohere (Embeddings) | Free tier | $0.00 |
| Bhashini (Translation) | Unlimited | $0.00 |
| Semantic Scholar | Free | $0.00 |
| **Total** | | **$1-5** |

### Realistic Scenario
- **$5-20 for entire PoC**
- OpenAI gives $5 free credit
- Effective cost: **$0-15**

### After PoC (Production: 100 users)
- **$50-100/month**
- Still far cheaper than GPU server (~$500/month)

---

## âš¡ Performance Comparison

| Metric | Local Models | API Approach | Improvement |
|--------|--------------|--------------|-------------|
| **First Startup** | 6-17 minutes | 2-3 seconds | **120x faster** |
| **Subsequent Startup** | 1-2 minutes | 2-3 seconds | **20x faster** |
| **Installation Size** | 8 GB | 400 MB | **95% smaller** |
| **Summarization Speed** | 2-5 seconds | 200-500ms | **5x faster** |
| **Embedding Speed** | 500ms-2s | 100-300ms | **3x faster** |
| **Translation Speed** | 1-3 seconds | 300-800ms | **3x faster** |
| **Concurrent Users** | 5-10 (CPU) | 1000+ | **100x more** |
| **Memory Usage** | 4-8 GB | 200-500 MB | **90% less** |
| **GPU Required** | Recommended | No | **Cost savings** |

---

## ðŸŽ¯ Hackathon Demo Benefits

### For Judges
1. **Instant startup** - No waiting for model loading
2. **Fast responses** - Truly feels instant
3. **Reliable** - No "out of memory" errors
4. **Scalable** - Can demo with multiple users simultaneously

### For Pitch
1. **"Powered by GPT-4 for best-in-class summarization"** âœ¨
2. **"Uses Government of India's Bhashini for translations"** ðŸ‡®ðŸ‡³
3. **"Can handle 1000+ concurrent users"** ðŸ“ˆ
4. **"Production-ready cloud architecture"** â˜ï¸

### For Evaluation Criteria
| Criteria | Score Impact |
|----------|--------------|
| Innovation (25%) | Higher (using GPT-4/Claude) |
| Accuracy (20%) | Higher (better models) |
| Usability (15%) | Much higher (instant) |
| Scalability (15%) | Much higher (cloud) |
| Privacy (10%) | Acceptable (academic use) |
| Impact (15%) | Same |

**Expected boost: +10-15 points in evaluation**

---

## ðŸ”’ Privacy & Compliance

### Data Sent to APIs
- Paper abstracts (public academic content)
- Research text (not personal data)
- No PII (Personally Identifiable Information)

### DPDP Act 2023 Compliance
âœ… No personal data sent to APIs
âœ… Research content is academic (public domain)
âœ… User authentication handled locally
âœ… Transparent about API usage in ToS

### User Consent
Add to Terms of Service:
> "This platform uses third-party AI services (OpenAI, Cohere) to process academic content. No personal information is shared. Research content may be processed by these services to provide summarization and analysis features."

---

## ðŸš¨ Risks & Mitigation

### Risk 1: API Downtime
**Mitigation**:
- Implement retry logic with exponential backoff
- Cache responses for common queries
- Provide graceful degradation (basic summaries if API fails)

### Risk 2: Rate Limits
**Mitigation**:
- Implement request queuing
- Use Cohere free tier (1000/month sufficient for PoC)
- Monitor usage with alerts

### Risk 3: Cost Overruns
**Mitigation**:
- Set hard limits in API dashboard ($50/month max)
- Cache heavily used queries
- Estimate: 8 users Ã— 10 queries/day Ã— 60 days = 4,800 queries (~$10)

### Risk 4: Internet Dependency
**Mitigation**:
- Acceptable for cloud-based platform
- Can add offline mode later if needed
- Most GDCs have reliable internet

---

## ðŸ“ˆ Scalability Path

### PoC (Now)
- 8 users
- API-based
- Cost: $5-20/month

### Pilot (3-6 months)
- 100 users
- API-based with caching
- Cost: $50-100/month

### Production (1+ year)
- 1000+ users
- Hybrid approach:
  - High-frequency queries â†’ Local models with GPU
  - Low-frequency queries â†’ APIs
  - Caching layer (Redis)
- Cost: $200-500/month (still cheaper than full GPU setup)

---

## âœ… Migration Checklist

### Pre-Migration
- [ ] Backup current codebase
- [ ] Create new branch `feature/api-migration`
- [ ] Sign up for API keys (OpenAI, Cohere, Bhashini)
- [ ] Set spending limits on API dashboards

### Migration
- [ ] Create `requirements-api.txt`
- [ ] Update `.env.example` with API keys
- [ ] Modify `literature_review_service.py`
- [ ] Modify `plagiarism_detection_service.py`
- [ ] Modify `journal_recommendation_service.py`
- [ ] Modify `translation_service.py`
- [ ] Add API client wrapper classes
- [ ] Implement error handling & retries
- [ ] Add response caching

### Testing
- [ ] Unit tests for each service
- [ ] Integration tests
- [ ] Load test (8 concurrent users)
- [ ] Verify all features work
- [ ] Test error scenarios (API down, rate limit)

### Documentation
- [ ] Update README.md
- [ ] Update ARCHITECTURE.md
- [ ] Update STATUS.md
- [ ] Create API_SETUP_GUIDE.md
- [ ] Update docker-compose.yml

### Deployment
- [ ] Test on clean environment
- [ ] Verify startup time < 5 seconds
- [ ] Verify response time < 1 second
- [ ] Update deployment scripts
- [ ] Create demo data

---

## ðŸŽ“ Learning Resources

### OpenAI API
- Docs: https://platform.openai.com/docs
- Pricing: https://openai.com/pricing
- Best practices: https://platform.openai.com/docs/guides/best-practices

### Cohere API
- Docs: https://docs.cohere.com
- Pricing: https://cohere.com/pricing
- Embeddings guide: https://docs.cohere.com/docs/embeddings

### Bhashini API
- Website: https://bhashini.gov.in
- ULCA Platform: https://bhashini.gov.in/ulca
- API Docs: Available after registration

---

## ðŸš€ Next Steps

1. **Review this plan** âœ… (you're here!)
2. **Get API keys** (10 minutes)
3. **Implement migration** (2-4 hours)
4. **Test thoroughly** (1 hour)
5. **Update documentation** (30 minutes)
6. **Demo preparation** (1 hour)

**Total time to fully API-based system: 4-6 hours**

---

## ðŸ“ž Support & Questions

**During Migration**:
- Check API status pages if issues occur
- Monitor API usage in dashboards
- Review error logs for API failures

**After Migration**:
- Set up monitoring alerts
- Review weekly usage reports
- Optimize based on actual usage patterns

---

## âœ¨ Expected Outcome

After migration, you'll have:

âœ… **Blazing fast system** (truly instant responses)
âœ… **Production-ready architecture** (scales to 1000+ users)
âœ… **Impressive demo** (no loading screens)
âœ… **Modern tech stack** (GPT-4, Cohere, Bhashini)
âœ… **Cost-effective** ($5-20 for entire PoC)
âœ… **Future-proof** (easy to upgrade models)

**This positions you to win the hackathon!** ðŸ†

---

**Last Updated**: November 3, 2025
**Document Version**: 1.0
**Status**: Ready for Implementation
